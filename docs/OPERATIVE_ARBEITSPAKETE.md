# Operative Arbeitspakete

Diese √úbersicht √ºbersetzt die Roadmap- und Next-Steps-Dokumente in konkrete Arbeitspakete. Jedes Paket enth√§lt Zielsetzung,
Abnahmekriterien, konkrete Aktivit√§ten, Validierungsschritte und empfohlene Dokumentationsartefakte. Die Pakete sind je
Agentenrolle gruppiert und priorisiert. Checkboxen markieren empfohlene Reihenfolgen.

> üîÑ **Update-Hinweis:** Nach der Bearbeitung eines Pakets sollten `python -m nova progress` und die CSV `Agenten_Aufgaben_Uebersicht.csv`
> aktualisiert werden, damit Reports und Dashboards den realen Stand widerspiegeln.

## Nova ‚Äì Foundation & Infrastruktur

### Paket N1 ‚Äì Container-Basis (Docker & Kubernetes)
- [x] **Ziel:** Docker- und Kubernetes-Laufzeit bereitstellen und mit Nova-CLI validieren.
- **Deliverables:**
  - Ausgef√ºllter Installationsreport laut `docs/FOUNDATION_CONTAINER_SETUP.md`.
  - Export `orchestration_journal/container-report.md` mit ‚úÖ Status.
  - Aktualisierte CSV-Zeile ‚ÄûDocker & Kubernetes-Cluster installieren‚Äú.
- **Aktivit√§ten:**
  1. Anleitung `docs/FOUNDATION_CONTAINER_SETUP.md` Schritt f√ºr Schritt durchgehen.
  2. F√ºr Entwicklungsumgebung Kind-Cluster erzeugen (`kind create cluster --name nova-foundation`).
  3. Produktionsnah kubeadm-/k3s-Setup vorbereiten; Konfiguration in `orchestration_journal/container-fix.md` protokollieren.
  4. Validierung: `python -m nova containers --export orchestration_journal/container-report.md`.
  5. Erfolg √ºber `docker run hello-world` und `kubectl get nodes` sichern.
- **Abnahme:** Alle Checks ‚úÖ, Report im Orchestrierungstagebuch verlinkt.

### Paket N2 ‚Äì VPN & Remote Access
- [x] **Ziel:** Gesicherte Zug√§nge via WireGuard oder OpenVPN bereitstellen.
- **Deliverables:**
  - Konfigurationsdateien (`infrastructure/vpn/<env>.conf` oder Vault-Eintrag) und Betriebsanleitung.
  - Markdown-Report `orchestration_journal/network/vpn_status.md` mit Testprotokoll.
- **Aktivit√§ten:**
  1. Anleitung `docs/FOUNDATION_VPN_SETUP.md` nutzen und Parameter in `nova/system/network.py` hinterlegen.
  2. Keys/Certificates generieren, Peer-Definitionen dokumentieren.
  3. Verbindung testen (`python -m nova network --vpn wireguard --export orchestration_journal/network/vpn_status.md`).
  4. Firewall- und Routingregeln erfassen.
- **Abnahme:** Erfolgreicher Ping/SSH √ºber VPN, Audit-Log im Journal.

### Paket N3 ‚Äì Security & Datenschutz
- [x] **Ziel:** Security Controls f√ºr Firewall, Anti-Virus und OPA-Policies belegen.
- **Deliverables:**
  - Audit-Report `orchestration_journal/security/audit_<datum>.log`.
  - Aktualisierte Findings-Liste `orchestration_journal/security/findings.md`.
- **Aktivit√§ten:**
  1. `docs/FOUNDATION_SECURITY_AUDIT.md` befolgen.
  2. `python -m nova audit --firewall enabled --antivirus enabled --policies enabled` ausf√ºhren.
  3. Findings eskalieren, Remediation-Tickets erstellen.
  4. Alert-Dry-Run dokumentieren (`python -m nova alerts --dry-run --export orchestration_journal/alerts.md`).
- **Abnahme:** Audit-Report ohne offene Findings, Definition-of-Done Security erf√ºllt.

### Paket N4 ‚Äì Backup & Recovery
- [x] **Ziel:** Wiederherstellungsf√§hige Sicherungen f√ºr Infrastruktur, Datenbanken und Modelle.
- **Deliverables:**
  - Backup-Plan `orchestration_journal/backups/backup_plan_default.md` (angepasst).
  - Restore-Drill-Protokoll `orchestration_journal/backups/drills/<datum>.md`.
- **Aktivit√§ten:**
  1. `docs/FOUNDATION_BACKUP_RECOVERY.md` durcharbeiten.
  2. Backup-Jobs f√ºr Kubernetes (Velero), Datenbanken (`pg_dump`, `mongodump`) und Artefakte konfigurieren.
  3. Monatlichen Restore-Test planen, Hash-Pr√ºfungen dokumentieren.
  4. `python -m nova backup --plan default --export orchestration_journal/backups/backup_plan_default.md` aktualisieren.
- **Abnahme:** Restore-Drill erfolgreich, CSV-Status gesetzt.

## Orion ‚Äì Model Operations

### Paket O1 ‚Äì NVIDIA NeMo Installationspfad
- [x] **Ziel:** Reproduzierbare Installation von NeMo inkl. Abh√§ngigkeiten.
- **Deliverables:**
  - Setup-Skript `orchestration_journal/model_ops/nemo_install.sh` oder Terraform/Ansible Playbook.
  - Validierungslog `orchestration_journal/model_ops/nemo_validation.md`.
- **Aktivit√§ten:**
  1. Anforderungen aus `docs/next_steps.md` Abschnitt ‚ÄûKI-Stack vorbereiten‚Äú √ºbernehmen.
  2. Container- oder Conda-Umgebung definieren; GPU-Support (CUDA Toolkit) dokumentieren.
  3. Test-Notebook/Script mit `nemo.collections.nlp` Beispiel laden.
  4. Ergebnisse via `python -m nova summary --agent orion` pr√ºfen.
- **Abnahme:** NeMo-Testskript l√§uft fehlerfrei, Dependencies versioniert.

### Paket O2 ‚Äì LLM Auswahl & Bereitstellung
- [x] **Ziel:** Arbeitsf√§higes Basismodell inklusive Bereitstellungskonzept.
- **Deliverables:**
  - Entscheidungsdokument `orchestration_journal/model_ops/llm_selection.md` mit Kriterien.
  - Deployment-Manifest (Helm Chart, Compose oder Terraform) im Repo-Pfad `nova/agents/llm_deployment/` (falls neu, Ordner anlegen).
- **Aktivit√§ten:**
  1. Kandidaten (Llama¬†3, Mixtral, etc.) bewerten: Lizenz, Parameter, HW-Bedarf.
  2. Deployment-Optionen (HF Inference Endpoint, TensorRT-LLM, vLLM) vergleichen.
  3. Proof-of-Concept mit `python -m nova agents --llm-status` erg√§nzen.
- **Abnahme:** Dokumentierte Entscheidung + lauff√§hige Bereitstellung in Testumgebung.

### Paket O3 ‚Äì Fine-Tuning Blueprint
- [x] **Ziel:** Standardisierter Prozess f√ºr datengest√ºtztes Finetuning.
- **Deliverables:**
  - Workflow-Diagramm `docs/diagrams/orion_finetuning_flow.png` (oder Markdown-Alternative).
  - Evaluationsplan `orchestration_journal/model_ops/finetuning_metrics.md`.
- **Aktivit√§ten:**
  1. Datenquellen inventarisieren, Annotationsstrategie skizzieren.
  2. Trainingspipeline (LoRA/PEFT) beschreiben; Parameter in YAML-Schablone hinterlegen.
  3. Automatisierte Tests definieren (`pytest` oder CLI `python -m nova qa --profile finetune`).
- **Abnahme:** Blueprint freigegeben, KPIs (BLEU, Rouge, Win-Rate) festgelegt.

## Lumina ‚Äì Daten & Speicher

### Paket L1 ‚Äì Datenbank-Automatisierung
- [x] **Ziel:** Automatisierte Bereitstellung von MongoDB & PostgreSQL.
- **Deliverables:**
  - Helm-Chart oder Compose-Datei `deploy/databases/docker-compose.yml`.
  - Betriebsdokumentation `orchestration_journal/data/db_operations.md`.
- **Aktivit√§ten:**
  1. Ports, Storage-Klassen, Backup-Hooks definieren.
  2. Healthchecks und Monitoring-Exporter (Prometheus) integrieren.
  3. `python -m nova monitoring --targets databases` f√ºr Smoke-Test erg√§nzen.
- **Abnahme:** Deployments laufen reproduzierbar, Monitoring liefert Metriken.

### Paket L2 ‚Äì Wissensbasis / VectorDB
- [x] **Ziel:** Wissensdatenbank (FAISS oder Pinecone) mit ingest-/query-Flow.
- **Deliverables:**
  - Architekturnotiz `orchestration_journal/data/vector_architecture.md`.
  - Ingestion-Skript `nova/task_queue/vector_ingest.py` (falls neu, Implementierung hinzuf√ºgen) samt Unit-Tests.
- **Aktivit√§ten:**
  1. Kandidaten bewerten (Kosten, Latenz, Self-Hosting) und Entscheidung festhalten.
  2. Prototypische Pipeline: Dokumente -> Embeddings -> Index.
  3. Integrationstest `pytest tests/vector_ingest_test.py` (neu anlegen bei Bedarf).
- **Abnahme:** Query-Demo liefert Treffer, Dokumentation vollst√§ndig.

## Echo ‚Äì Interaktionsdesign

### Paket E1 ‚Äì ACE Stack Validierung
- [x] **Ziel:** Riva, Audio2Face und NeMo in funktionsf√§higem Zusammenspiel.
- **Deliverables:**
  - Installationsmatrix `orchestration_journal/experience/ace_components.md`.
  - Testprotokoll `orchestration_journal/experience/ace_validation.log`.
- **Aktivit√§ten:**
  1. Container-Images identifizieren, Lizenzabh√§ngigkeiten pr√ºfen.
  2. Beispiel-Dialog √ºber Riva (ASR ‚Üí TTS) durchf√ºhren.
  3. Audio2Face-Szene mit Sample-Animation exportieren.
- **Abnahme:** End-to-End-Demo dokumentiert, offene Risiken aufgef√ºhrt.

### Paket E2 ‚Äì Avatar Pipeline
- [x] **Ziel:** Dokumentierte Pipeline von Omniverse bis Teams/Frontend.
- **Deliverables:**
  - Sequenzdiagramm `docs/diagrams/avatar_pipeline.drawio`.
  - Betriebshandbuch `orchestration_journal/experience/avatar_runbook.md`.
- **Aktivit√§ten:**
  1. Omniverse-Szene definieren, Animations-Trigger festlegen.
  2. Audio2Face-Lip-Sync einbinden, Exportpfad zu Riva validieren.
  3. Teams/WebRTC-Integration planen (Auth, QoS, Bandbreite).
- **Abnahme:** Pipeline-Dokumentation vollst√§ndig, Integrationsrisiken adressiert.

## Chronos ‚Äì Automatisierung & Workflow

### Paket C1 ‚Äì n8n Grundinstallation
- [x] **Ziel:** Laufende n8n-Instanz mit Beispiel-Workflows.
- **Deliverables:**
  - Deployment-Skript `deploy/automation/n8n/docker-compose.yml` oder Kubernetes-Manifeste.
  - Workflow-Export `orchestration_journal/automation/n8n_sample_workflow.json`.
- **Aktivit√§ten:**
  1. Installationsanleitung (Docker/Kubernetes) dokumentieren.
  2. Beispiel-Workflow: Webhook ‚Üí LangChain-Task ‚Üí Slack/Teams Notification.
  3. Healthcheck-URL in Monitoring aufnehmen.
- **Abnahme:** Workflow l√§sst sich triggern, Logs liegen im Journal.

### Paket C2 ‚Äì Data Flywheel & CI/CD
- [x] **Ziel:** Konzept f√ºr automatisiertes Feedback & Deployment.
- **Deliverables:**
  - Blueprint `docs/automation/data_flywheel_blueprint.md`.
  - CI/CD-Plan `orchestration_journal/automation/cicd_plan.md` (GitHub Enterprise + Kubernetes).
- **Aktivit√§ten:**
  1. Datenquellen f√ºr Feedback (User Logs, KPI) identifizieren.
  2. Automatisierte Retraining-Triggers definieren.
  3. Pipeline-Schritte (Lint, Tests, Deploy) festhalten; Github Actions/Vault-Integration beschreiben.
- **Abnahme:** Stakeholder sign-off, Tickets f√ºr Umsetzung erstellt.

## Aura ‚Äì Monitoring & Dashboards

### Paket A1 ‚Äì Grafana & Observability Stack
- [x] **Ziel:** Observability-Setup mit Prometheus/Grafana.
- **Deliverables:**
  - Deployment-Manifest `deploy/monitoring/grafana-stack.yml`.
  - Dashboard-Export `orchestration_journal/monitoring/grafana_dashboards.json`.
- **Aktivit√§ten:**
  1. Prometheus-Scrape-Targets definieren (Kubernetes, Datenbanken, LLM Service).
  2. Alerts in `python -m nova alerts` spiegeln.
  3. Zugriffskonzept und Nutzerrollen dokumentieren.
- **Abnahme:** Dashboards visualisieren Kernmetriken, Alerts getestet.

### Paket A2 ‚Äì LUX Dashboard & Stimmungsanalyse
- [x] **Ziel:** UX-Mockups + Telemetrie-Anbindung f√ºr emotionales Feedback.
- **Deliverables:**
  - Wireframes `docs/dashboards/lux_dashboard_wireframes.pdf` (oder Markdown-Link).
  - KPI-Definition `nova/logging/kpi/lux_metrics.md`.
- **Aktivit√§ten:**
  1. Anforderungen aus Stakeholder-Interviews zusammentragen.
  2. Datenquellen (Sentiment-Analyse, Energieverbrauch) definieren.
  3. Prototypische Daten-Pipeline skizzieren (`nova/monitoring/ingest.py`).
- **Abnahme:** Wireframes abgestimmt, KPI-Katalog freigegeben.

---

### Arbeitsablauf & Governance
1. W√§hle pro Sprint 2‚Äì3 Pakete mit h√∂chster Priorit√§t aus den Foundation-Bereichen.
2. Dokumentiere Fortschritte direkt im `orchestration_journal/`-Ordner.
3. Pflege Definition-of-Done (`docs/DEFINITION_OF_DONE.md`) und Roadmap (`README.md`) nach Abschluss.
4. Trigger Regressionstests (`pytest`, `python -m nova qa`) bevor neue Pakete gestartet werden.

Mit diesen Arbeitspaketen lassen sich die vorhandenen Planungsdokumente in konkrete, sofort ausf√ºhrbare Aufgaben √ºberf√ºhren.
